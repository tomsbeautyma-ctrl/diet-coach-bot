// server.js  â€”â€” ESM ç‰ˆï¼ˆ"type": "module" å‰æï¼‰

import express from "express";
import { Client, middleware as lineMW } from "@line/bot-sdk";
import OpenAI from "openai";

const PORT = process.env.PORT || 10000;

// ====== App ======
const app = express();
// â€» ã‚°ãƒ­ãƒ¼ãƒãƒ«ã« app.use(express.json()) ã¯å…¥ã‚Œãªã„ã§OK
//    ï¼ˆLINEã®ç½²åæ¤œè¨¼ã« raw body ãŒå¿…è¦ã€‚lineMW ãŒé¢å€’è¦‹ã¾ã™ï¼‰

// ====== Health & Ping ======
app.get("/", (_req, res) => res.status(200).send("alive"));
app.get("/health", (_req, res) => res.status(200).send("ok"));

// ====== LINE SDK è¨­å®š ======
const lineConfig = {
  channelAccessToken: process.env.LINE_CHANNEL_ACCESS_TOKEN,
  channelSecret: process.env.LINE_CHANNEL_SECRET,
};
const lineClient = new Client(lineConfig);

// ====== OpenAI(DeepInfra) è¨­å®š ======
const ai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,       // DeepInfra ã® API ã‚­ãƒ¼
  baseURL: process.env.OPENAI_BASE_URL,     // ä¾‹: https://api.deepinfra.com/v1/openai
});

// ====== ãƒ‡ãƒãƒƒã‚°ç”¨ï¼ˆGET ã§ã‚‚ç”Ÿå­˜ç¢ºèªã§ãã‚‹ï¼‰ ======
app.get("/webhook/line", (_req, res) => {
  res
    .status(200)
    .send("LINE webhook endpoint is alive (POST from LINE required).");
});

// ====== æœ¬ç•ª: LINE Webhook (POST) ======
app.post("/webhook/line", lineMW(lineConfig), async (req, res) => {
  try {
    const events = req.body?.events || [];

    await Promise.all(
      events.map(async (event) => {
        if (event.type !== "message" || event.message.type !== "text") return;

        const userText = (event.message.text || "").trim();

        // DeepInfra (OpenAI äº’æ›) ã«æŠ•ã’ã‚‹
        const aiRes = await ai.chat.completions.create({
          model: "meta-llama/Meta-Llama-3.1-8B-Instruct",
          messages: [
            {
              role: "system",
              content:
                "You are a supportive Japanese fitness & styling assistant.",
            },
            { role: "user", content: userText },
          ],
          temperature: 0.4,
          max_tokens: 500,
        });

        const reply =
          aiRes?.choices?.[0]?.message?.content?.trim() ||
          "ã†ã¾ãç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠé¡˜ã„ã—ã¾ã™ã€‚";

        await lineClient.replyMessage(event.replyToken, [
          { type: "text", text: reply },
        ]);
      })
    );

    // â˜…å¿…ãš200ã‚’è¿”ã™ï¼ˆLINEã¯ã“ã‚Œã‚’æœŸå¾…ï¼‰
    res.status(200).end();
  } catch (err) {
    console.error("Webhook error:", err);
    // ç½²åã‚¨ãƒ©ãƒ¼ç­‰ã§ã‚‚ 200 ã‚’è¿”ã—ã€LINE ã®å†é€ã‚’é¿ã‘ã‚‹
    res.status(200).end();
  }
});

// ====== DeepInfra å˜ä½“ãƒ†ã‚¹ãƒˆç”¨ ======
app.get("/test/ai", async (_req, res) => {
  try {
    const r = await ai.chat.completions.create({
      model: "meta-llama/Meta-Llama-3.1-8B-Instruct",
      messages: [{ role: "user", content: "æ¥ç¶šãƒ†ã‚¹ãƒˆã€‚1è¡Œã§è¿”ç­”ã—ã¦ã€‚" }],
      max_tokens: 40,
    });
    res.json({ ok: true, text: r.choices?.[0]?.message?.content || "" });
  } catch (e) {
    console.error("âŒ /test/ai error:", e);
    res.status(500).json({ ok: false, name: e.name, message: e.message });
  }
});

// ====== Listen ======
app.listen(PORT, () => {
  console.log(`ğŸš€ Server started on port ${PORT}`);
});
